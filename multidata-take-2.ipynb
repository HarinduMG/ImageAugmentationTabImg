{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11632427,"sourceType":"datasetVersion","datasetId":7298424},{"sourceId":11645692,"sourceType":"datasetVersion","datasetId":7307789},{"sourceId":14290774,"sourceType":"datasetVersion","datasetId":9122006}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport jax\n#---------------------------------------\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#---------------------------------------\nimport tensorflow as tf\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout,Flatten\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#---------------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:02:59.078478Z","iopub.execute_input":"2025-12-27T01:02:59.079261Z","iopub.status.idle":"2025-12-27T01:03:23.021560Z","shell.execute_reply.started":"2025-12-27T01:02:59.079234Z","shell.execute_reply":"2025-12-27T01:03:23.020932Z"}},"outputs":[{"name":"stderr","text":"2025-12-27 01:03:08.683106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766797389.269188      38 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766797389.408554      38 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"temp_dir = \"/kaggle/input/templates/Templates\"\ndataset_dir = \"/kaggle/input/cytomorphology/PKG - AML-Cytomorphology_MLL_Helmholtz_v1/data\"\nexcel_path = \"/kaggle/input/preprocessed-xlsx/Preprocessed clinical data.xlsx\"\n\nimage11v = 0,0,0\nimage12v = 10,10,10\nimage21v = 20,20,20\nimage22v = 30,30,30\nsexv = 50,50,50\nagev = 70,70,70\nper_ulv = 90,90,90\npb_myebv = 100,100,100\npb_promv = 120,120,120\npb_myelv = 140,140,140\npb_metav = 160,160,160\npb_neutbv = 180,180,180\npb_neutsv = 200,200,200\npb_eosiv = 220,220,220\npb_basov = 240,240,240\npb_monov = 250,250,250\npb_lymtv = 230,230,230\npb_lymarv = 210,210,210\npb_lymanv = 190,190,190\npb_ov = 170,170,170","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:03:23.022633Z","iopub.execute_input":"2025-12-27T01:03:23.023154Z","iopub.status.idle":"2025-12-27T01:03:23.028384Z","shell.execute_reply.started":"2025-12-27T01:03:23.023133Z","shell.execute_reply":"2025-12-27T01:03:23.027794Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"datamap = [\n    [\"image11\", image11v],\n    [\"image12\", image12v],\n    [\"image21\", image21v],\n    [\"image22\", image22v],\n    [\"sex\", sexv],\n    [\"age\", agev],\n    [\"per_ul\", per_ulv],\n    [\"pb_myeb\", pb_myebv],\n    [\"pb_prom\", pb_promv],\n    [\"pb_myel\", pb_myelv],\n    [\"pb_meta\", pb_metav],\n    [\"pb_neutb\", pb_neutbv],\n    [\"pb_neuts\", pb_neutsv],\n    [\"pb_eosi\", pb_eosiv],\n    [\"pb_baso\", pb_basov],\n    [\"pb_mono\", pb_monov],\n    [\"pb_lymt\", pb_lymtv],\n    [\"pb_lymar\", pb_lymarv],\n    [\"pb_lyman\", pb_lymanv],\n    [\"pb_o\", pb_ov]\n]\n\nimagemap = [\n    [\"pb_myeb\", (255,0,0)],\n    [\"pb_prom\", (255,128,0)],\n    [\"pb_myel\", (255,255,0)],\n    [\"pb_meta\", (128,255,0)],\n    [\"pb_neutb\", (0,255,0)],\n    [\"pb_neuts\", (0,255,128)],\n    [\"pb_eosi\", (0,255,255)],\n    [\"pb_baso\", (0,128,255)],\n    [\"pb_mono\", (0,0,255)],\n    [\"pb_lymt\", (128,0,255)],\n    [\"pb_lymar\", (255,0,255)],\n    [\"pb_lyman\", (255,0,128)],\n    [\"pb_o\", (255,255,255)]\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:03:23.029091Z","iopub.execute_input":"2025-12-27T01:03:23.029281Z","iopub.status.idle":"2025-12-27T01:03:23.056655Z","shell.execute_reply.started":"2025-12-27T01:03:23.029266Z","shell.execute_reply":"2025-12-27T01:03:23.056049Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"### function to return mapping\n\ndef check(x, arr=datamap):\n    mapping = dict(arr)\n    \n    # Add reverse mappings too\n    reverse_mapping = {v: k for k, v in arr}\n    mapping.update(reverse_mapping)\n\n    if x in mapping:\n        return mapping[x]\n    else:\n        raise KeyError(f\"No mapping found for '{x}'\")\n\n### function to replace a regions with a certain color\n\ndef readTemplate(template_path):\n    image = cv2.imread(template_path)\n    h, w, _ = image.shape\n    \n    splitData = np.zeros((len(datamap), h, w), dtype=np.uint8)\n    \n    for i in range(h):\n        for j in range(w):\n            pixel = tuple(image[i, j])          # Make hashable\n            dataType = check(pixel)\n            index = next(k for k, pair in enumerate(datamap) if pair[0] == dataType)\n            splitData[index, i, j] = 1\n\n    return splitData\n\ndef altData(data, templateData, arr1 = datamap, arr2 = imagemap):\n    returningData = np.zeros((16,164,164,3))\n\n    #print(data.shape)\n\n    #Handling sex\n    if data[0] == 0:\n        returningData[0] = (0,128,255)\n    else:\n        returningData[0] = (255,0,128)\n\n    #age\n    returningData[1] = (data[1] / 100)*np.array([111, 0, 255])\n    \n    #per_ul\n    returningData[2] = (data[2]/270)*np.array([128,255,0])\n\n    #rest of the data follow the same pattern\n    for i in range(len(imagemap)):\n        #print(i)\n        imageMapVAR = np.array([imagemap[i][1]])\n        Template = np.array([templateData[i+4]])\n\n        imageMapVAR = imageMapVAR.reshape(1,1,3)\n        Template = Template[...,None]\n\n        #print((data[i+1]/100))\n        plt.imshow(imageMapVAR)\n        plt.imshow(Template[0])\n        #print((data[i+1]/100).shape)\n        #print(imageMapVAR.shape)\n        #print(Template.shape)\n        \n        returningData[i] = (data[i+1]/100)*imageMapVAR*Template\n    \n    return returningData","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:03:23.058088Z","iopub.execute_input":"2025-12-27T01:03:23.058394Z","iopub.status.idle":"2025-12-27T01:03:23.082255Z","shell.execute_reply.started":"2025-12-27T01:03:23.058373Z","shell.execute_reply":"2025-12-27T01:03:23.081698Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\"\"\"data_class_list = os.listdir(dataset_dir)\ntemplates = os.listdir(temp_dir)\n\n#print(templates)\n\nnewDataPath = \"/kaggle/working/NewDataset/\"\n\ndf = pd.read_excel(excel_path, engine='openpyxl')\n\nfor template in templates:\n    template_path = os.path.join(temp_dir,template)\n\n    newpath = os.path.join(newDataPath,template)\n    #print(template_path)\n    #print(newpath)\n\n    for index, row in df.iterrows():\n        ID = row['patient_id']\n        sex = row['sex_1f_2m']\n        age = row['age']\n        data = row[4:18]\n        data = data.fillna(0)\n        fullData = sex + age + data\n        #print(fullData)\n        for classs in data_class_list:\n            class_path = os.path.join(dataset_dir,classs)\n\n            newClassPath = os.path.join(newpath,classs)\n            \n            patient_path = os.path.join(class_path,ID)\n            \n            if os.path.isdir(patient_path):\n                newPatientPath = os.path.join(newClassPath,ID)\n                os.makedirs(newPatientPath, exist_ok=True)\n                image_list = os.listdir(patient_path)\n\n                for image in image_list:\n                    image_path = os.path.join(patient_path,image)\n                    filename = os.path.splitext(image)[0] + \".png\"\n                    newImagePath = os.path.join(newPatientPath, filename)\n\n                    #print(image_path)\n\n                    image = cv2.imread(image_path)\n                    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n                    #print(image.shape)\n        \n                    part_11 = image[0:72, 0:72]\n                    part_12 = image[0:72, 72:144]\n                    part_21 = image[72:144, 0:72]\n                    part_22 = image[72:144, 72:144]\n\n\n                    parts = [part_11,part_12,part_21,part_22]\n\n                    image_values = [image11v,image12v,image21v,image22v]        \n                    \n                    templateData = readTemplate(template_path)\n                    #print(templateData.shape)\n                    \n                    imageArray = np.zeros((4, templateData[0].shape[0], templateData[0].shape[1],3))\n                    \n\n                    for sector in image_values:\n                        rows, cols = np.where(templateData[image_values.index(sector)] == 1)\n                        r_min, r_max = rows.min(), rows.max() + 1\n                        c_min, c_max = cols.min(), cols.max() + 1\n\n                        imageArray[image_values.index(sector)][r_min:r_max, c_min:c_max] = parts[image_values.index(sector)]\n                    dataPoints = altData(fullData,templateData)\n\n                    #print(imageArray.shape)\n\n                    Final_image3D = np.concatenate((imageArray, dataPoints), axis=0)\n\n                    Final_image = np.sum(Final_image3D, axis=0)\n                    os.makedirs(newPatientPath, exist_ok=True)\n                    cv2.imwrite(newImagePath, Final_image)\n                    #print(\"==============================================================================\")\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:03:23.082890Z","iopub.execute_input":"2025-12-27T01:03:23.083086Z","iopub.status.idle":"2025-12-27T01:03:23.107108Z","shell.execute_reply.started":"2025-12-27T01:03:23.083072Z","shell.execute_reply":"2025-12-27T01:03:23.106370Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'data_class_list = os.listdir(dataset_dir)\\ntemplates = os.listdir(temp_dir)\\n\\n#print(templates)\\n\\nnewDataPath = \"/kaggle/working/NewDataset/\"\\n\\ndf = pd.read_excel(excel_path, engine=\\'openpyxl\\')\\n\\nfor template in templates:\\n    template_path = os.path.join(temp_dir,template)\\n\\n    newpath = os.path.join(newDataPath,template)\\n    #print(template_path)\\n    #print(newpath)\\n\\n    for index, row in df.iterrows():\\n        ID = row[\\'patient_id\\']\\n        sex = row[\\'sex_1f_2m\\']\\n        age = row[\\'age\\']\\n        data = row[4:18]\\n        data = data.fillna(0)\\n        fullData = sex + age + data\\n        #print(fullData)\\n        for classs in data_class_list:\\n            class_path = os.path.join(dataset_dir,classs)\\n\\n            newClassPath = os.path.join(newpath,classs)\\n            \\n            patient_path = os.path.join(class_path,ID)\\n            \\n            if os.path.isdir(patient_path):\\n                newPatientPath = os.path.join(newClassPath,ID)\\n                os.makedirs(newPatientPath, exist_ok=True)\\n                image_list = os.listdir(patient_path)\\n\\n                for image in image_list:\\n                    image_path = os.path.join(patient_path,image)\\n                    filename = os.path.splitext(image)[0] + \".png\"\\n                    newImagePath = os.path.join(newPatientPath, filename)\\n\\n                    #print(image_path)\\n\\n                    image = cv2.imread(image_path)\\n                    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n\\n                    #print(image.shape)\\n        \\n                    part_11 = image[0:72, 0:72]\\n                    part_12 = image[0:72, 72:144]\\n                    part_21 = image[72:144, 0:72]\\n                    part_22 = image[72:144, 72:144]\\n\\n\\n                    parts = [part_11,part_12,part_21,part_22]\\n\\n                    image_values = [image11v,image12v,image21v,image22v]        \\n                    \\n                    templateData = readTemplate(template_path)\\n                    #print(templateData.shape)\\n                    \\n                    imageArray = np.zeros((4, templateData[0].shape[0], templateData[0].shape[1],3))\\n                    \\n\\n                    for sector in image_values:\\n                        rows, cols = np.where(templateData[image_values.index(sector)] == 1)\\n                        r_min, r_max = rows.min(), rows.max() + 1\\n                        c_min, c_max = cols.min(), cols.max() + 1\\n\\n                        imageArray[image_values.index(sector)][r_min:r_max, c_min:c_max] = parts[image_values.index(sector)]\\n                    dataPoints = altData(fullData,templateData)\\n\\n                    #print(imageArray.shape)\\n\\n                    Final_image3D = np.concatenate((imageArray, dataPoints), axis=0)\\n\\n                    Final_image = np.sum(Final_image3D, axis=0)\\n                    os.makedirs(newPatientPath, exist_ok=True)\\n                    cv2.imwrite(newImagePath, Final_image)\\n                    #print(\"==============================================================================\")'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Complete GPU-accelerated dataset generation script for Kaggle\n# Assumptions:\n#  - CUDA-enabled GPU is available in the runtime\n#  - OpenCV (cv2), pandas, numpy are available (standard Kaggle)\n#  - The user-provided variables (datamap, imagemap, image11v, etc.) are present\n#  - Template images are same resolution as code expects (h x w; code reads them dynamically)\n\nimport os\nimport sys\nimport math\nimport subprocess\nfrom tqdm import tqdm\n\n# Try import cupy; if not installed try to pip install a GPU build.\ntry:\n    import cupy as cp\nexcept Exception as e:\n    print(\"CuPy not found. Attempting to install cupy-cuda from pip (this may take a while)...\")\n    # choose the appropriate cupy-cuda version for the Kaggle CUDA version; common is cuda11x or cuda12x.\n    # If you know exact cuda version, change `cupy-cuda12x` accordingly.\n    install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"cupy-cuda12x\"]\n    subprocess.check_call(install_cmd)\n    import cupy as cp\n\nimport numpy as np\nimport cv2\nimport pandas as pd\n\n# ---------------------------\n# User-provided variables\n# (You already gave these values; they are repeated here for the script to be self-contained)\n# ---------------------------\ntemp_dir = \"/kaggle/input/templates/Templates\"\ndataset_dir = \"/kaggle/input/cytomorphology/PKG - AML-Cytomorphology_MLL_Helmholtz_v1/data\"\nexcel_path = \"/kaggle/input/preprocessed-xlsx/Preprocessed clinical data.xlsx\"\n\nimage11v = (0,0,0)\nimage12v = (10,10,10)\nimage21v = (20,20,20)\nimage22v = (30,30,30)\nsexv = (50,50,50)\nagev = (70,70,70)\nper_ulv = (90,90,90)\npb_myebv = (100,100,100)\npb_promv = (120,120,120)\npb_myelv = (140,140,140)\npb_metav = (160,160,160)\npb_neutbv = (180,180,180)\npb_neutsv = (200,200,200)\npb_eosiv = (220,220,220)\npb_basov = (240,240,240)\npb_monov = (250,250,250)\npb_lymtv = (230,230,230)\npb_lymarv = (210,210,210)\npb_lymanv = (190,190,190)\npb_ov = (170,170,170)\n\ndatamap = [\n    [\"image11\", image11v],\n    [\"image12\", image12v],\n    [\"image21\", image21v],\n    [\"image22\", image22v],\n    [\"sex\", sexv],\n    [\"age\", agev],\n    [\"per_ul\", per_ulv],\n    [\"pb_myeb\", pb_myebv],\n    [\"pb_prom\", pb_promv],\n    [\"pb_myel\", pb_myelv],\n    [\"pb_meta\", pb_metav],\n    [\"pb_neutb\", pb_neutbv],\n    [\"pb_neuts\", pb_neutsv],\n    [\"pb_eosi\", pb_eosiv],\n    [\"pb_baso\", pb_basov],\n    [\"pb_mono\", pb_monov],\n    [\"pb_lymt\", pb_lymtv],\n    [\"pb_lymar\", pb_lymarv],\n    [\"pb_lyman\", pb_lymanv],\n    [\"pb_o\", pb_ov]\n]\n\nimagemap = [\n    [\"pb_myeb\", (255,0,0)],\n    [\"pb_prom\", (255,128,0)],\n    [\"pb_myel\", (255,255,0)],\n    [\"pb_meta\", (128,255,0)],\n    [\"pb_neutb\", (0,255,0)],\n    [\"pb_neuts\", (0,255,128)],\n    [\"pb_eosi\", (0,255,255)],\n    [\"pb_baso\", (0,128,255)],\n    [\"pb_mono\", (0,0,255)],\n    [\"pb_lymt\", (128,0,255)],\n    [\"pb_lymar\", (255,0,255)],\n    [\"pb_lyman\", (255,0,128)],\n    [\"pb_o\", (255,255,255)]\n]\n\n# Which labels represent the four image quadrants (BGR tuples)\nimage_values = [image11v, image12v, image21v, image22v]\n\n# Output path\nnewDataPath = \"/kaggle/working/NewDataset_gpu/\"\nos.makedirs(newDataPath, exist_ok=True)\n\n# ---------------------------\n# Helper functions (GPU)\n# ---------------------------\n\n# Create quick lookup maps (label -> color tuple) on CPU (small structures)\nlabel_to_color = {label: tuple(color) for label, color in datamap}\nlabel_to_index = {label: idx for idx, (label, _) in enumerate(datamap)}\n\n# NOTE: cv2.imread returns BGR. The datamap tuples are interpreted as BGR tuples here.\n# If your datamap colors are RGB instead, swap channels when comparing (or use cv2.cvtColor).\n\ndef readTemplate_gpu(template_path):\n    \"\"\"\n    Reads template using OpenCV then creates a boolean mask per datamap key on the GPU.\n    Returns: templateData -> cp.ndarray shape (len(datamap), h, w), dtype=uint8 (0/1)\n    \"\"\"\n    img = cv2.imread(template_path)  # BGR uint8\n    if img is None:\n        raise FileNotFoundError(f\"Template not found: {template_path}\")\n\n    h, w, _ = img.shape\n\n    # Move image to GPU (uint8)\n    img_gpu = cp.asarray(img, dtype=cp.uint8)  # shape (h,w,3)\n\n    n_keys = len(datamap)\n    templateData = cp.zeros((n_keys, h, w), dtype=cp.uint8)\n\n    # Vectorized per-key masks\n    for idx, (label, color_tuple) in enumerate(datamap):\n        # color_tuple assumed to be (B, G, R) matching cv2.imread order\n        b, g, r = color_tuple\n        # build boolean mask where all channels match\n        mask = (img_gpu[:,:,0] == int(b)) & (img_gpu[:,:,1] == int(g)) & (img_gpu[:,:,2] == int(r))\n        templateData[idx] = mask.astype(cp.uint8)\n\n    return templateData  # on GPU\n\n\ndef altData_gpu(fullData_list, templateData):\n    \"\"\"\n    Build the data overlays (the colored channel contributions) on GPU.\n    fullData_list: CPU list or 1D numpy array of numeric values [sex, age, ... other features ...]\n    templateData: cp.ndarray (n_keys, h, w) - provided by readTemplate_gpu\n    Returns cp.ndarray shape (4 + len(imagemap), h, w, 3), dtype=float32\n    Index mapping:\n      0..3 => reserved for quadrants (we will return only the \"data overlays\" portion here starting index 4)\n    \"\"\"\n    # Convert fullData to GPU array (float)\n    fd = cp.asarray(fullData_list, dtype=cp.float32)\n\n    h = int(templateData.shape[1])\n    w = int(templateData.shape[2])\n\n    n_imagemap = len(imagemap)\n    out_count = 4 + n_imagemap\n    returningData = cp.zeros((out_count, h, w, 3), dtype=cp.float32)\n\n    # 0: sex coloring (using provided sexv colors as BGR tuples)\n    # We expect fullData_list[0] to be sex (0 or 1 or whatever numeric). Normalize / scale as per previous logic.\n    sex_val = float(fullData_list[0]) if len(fullData_list) > 0 else 0.0\n    # If sex_val == 0 -> use one color else other (match prior logic)\n    sex_color = cp.array([0,128,255], dtype=cp.float32) if sex_val == 0 else cp.array([255,0,128], dtype=cp.float32)\n    returningData[0] = sex_color.reshape(1,1,3)\n\n    # 1: age (previous code used (age/100)*[111,0,255])\n    age_val = float(fullData_list[1]) if len(fullData_list) > 1 else 0.0\n    returningData[1] = (age_val / 100.0) * cp.array([111.0, 0.0, 255.0], dtype=cp.float32).reshape(1,1,3)\n\n    # 2: per_ul (used denom 270 in earlier code)\n    per_ul_val = float(fullData_list[2]) if len(fullData_list) > 2 else 0.0\n    returningData[2] = (per_ul_val / 270.0) * cp.array([128.0,255.0,0.0], dtype=cp.float32).reshape(1,1,3)\n\n    # Index 3 left unused for symmetry with \"4 quadrants\" in main assembly (we can leave zeros)\n    returningData[3] = cp.zeros((1,1,3), dtype=cp.float32)\n\n    # Now for each imagemap entry, scale the color by corresponding fullData value, and mask with templateData\n    # We need to map imagemap entry label to a position in fullData_list.\n    # In your original code you used data[i+1] indexing; here we assume the sequence in fullData_list follows:\n    # [sex, age, per_ul, pb_myeb, pb_prom, pb_myel, pb_meta, pb_neutb, pb_neuts, pb_eosi, pb_baso,\n    #  pb_mono, pb_lymt, pb_lymar, pb_lyman, pb_o]\n    # That is: fullData_list[3 + j] corresponds to imagemap[j]\n    for j, (label, color_tuple) in enumerate(imagemap):\n        # get the corresponding numeric feature value (safe-check index)\n        feature_index = 3 + j  # as per mapping assumption above\n        feature_val = float(fullData_list[feature_index]) if feature_index < len(fullData_list) else 0.0\n        # color as float on GPU (BGR)\n        color_vec = cp.asarray(color_tuple, dtype=cp.float32).reshape(1,1,3)\n        # mask uses templateData entry for the corresponding datamap label index:\n        # We need to find which index in datamap corresponds to this label\n        if label not in label_to_index:\n            # skip if absent\n            continue\n        datamap_idx = label_to_index[label]\n        mask = templateData[datamap_idx].astype(cp.float32)  # shape (h,w)\n        mask3 = mask[..., None]  # shape (h,w,1)\n\n        # scaled contribution\n        contribution = (feature_val / 100.0) * color_vec * mask3  # (h,w,3)\n        returningData[4 + j] = contribution\n\n    return returningData  # shape (4 + n_imagemap, h, w, 3)\n\n\n# ---------------------------\n# Main processing loop\n# ---------------------------\n\n# Read dataframe\ndf = pd.read_excel(excel_path, engine='openpyxl')\n\n# Templates list\ntemplates = [f for f in os.listdir(temp_dir) if os.path.isfile(os.path.join(temp_dir, f))]\n\ndata_class_list = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n\n# For faster repeated access, build mapping from datamap tuples -> datamap index\n# datamap is list of [label, (B,G,R)]\ncolor_to_datamap_index = {tuple(pair[1]): idx for idx, pair in enumerate(datamap)}\n\n# Iterate templates\nfor template_name in tqdm(templates, desc=\"Templates\"):\n    template_path = os.path.join(temp_dir, template_name)\n    print(f\"Processing template: {template_path}\")\n\n    # Prepare output folder per-template\n    newpath = os.path.join(newDataPath, template_name)\n    os.makedirs(newpath, exist_ok=True)\n\n    # Read template once (GPU)\n    templateData = readTemplate_gpu(template_path)  # shape (len(datamap), h, w) on GPU\n    h = int(templateData.shape[1])\n    w = int(templateData.shape[2])\n\n    # precompute indices of quadrant datamap entries (so we know which template masks correspond to quadrant)\n    quadrant_labels = ['image11', 'image12', 'image21', 'image22']\n    quadrant_datamap_indices = [label_to_index.get(lbl) for lbl in quadrant_labels]\n    # If any is None, script will still attempt to run but will skip empty ones.\n\n    # iterate over patient rows\n    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Patients\", leave=False):\n        ID = str(row['patient_id'])\n        sex = row['sex_1f_2m']\n        age = row['age']\n        data_series = row[4:18].fillna(0)  # as user did earlier\n\n        # Build fullData_list: [sex, age] + other fields in same order expected\n        # We need this order to align with altData_gpu's expectations (feature indices).\n        # The user previously used: fullData = sex + age + data  (ambiguous), so we will construct:\n        fullData_list = [float(sex), float(age)] + [float(x) for x in data_series.tolist()]\n\n        # For each data class folder (classs)\n        for classs in data_class_list:\n            class_path = os.path.join(dataset_dir, classs)\n            newClassPath = os.path.join(newpath, classs)\n            patient_path = os.path.join(class_path, ID)\n\n            if not os.path.isdir(patient_path):\n                continue\n\n            newPatientPath = os.path.join(newClassPath, ID)\n            os.makedirs(newPatientPath, exist_ok=True)\n\n            image_list = [f for f in os.listdir(patient_path) if os.path.isfile(os.path.join(patient_path, f))]\n\n            for img_name in image_list:\n                image_path = os.path.join(patient_path, img_name)\n                filename = os.path.splitext(img_name)[0] + \".png\"\n                newImagePath = os.path.join(newPatientPath, filename)\n\n                # read whole image (BGR)\n                image = cv2.imread(image_path)\n                if image is None:\n                    print(f\"Warning: couldn't read {image_path}. Skipping.\")\n                    continue\n\n                # If the images are 144x144 and split into 4 quadrants of 72x72 each, as in the original code:\n                # Extract quadrants (careful with indexing)\n                ih, iw = image.shape[:2]\n                # compute quadrant sizes dynamically (assume 2x2 tiling)\n                ch = ih // 2\n                cw = iw // 2\n                part_11 = image[0:ch, 0:cw]           # top-left\n                part_12 = image[0:ch, cw:2*cw]        # top-right\n                part_21 = image[ch:2*ch, 0:cw]        # bottom-left\n                part_22 = image[ch:2*ch, cw:2*cw]     # bottom-right\n\n                parts = [part_11, part_12, part_21, part_22]  # CPU numpy arrays\n\n                # Prepare GPU imageArray for quadrants: shape (4, h, w, 3)\n                imageArray = cp.zeros((4, h, w, 3), dtype=cp.float32)\n\n                # For each quadrant, find region in templateData and paste the part (moved to GPU)\n                for q_idx, datamap_idx in enumerate(quadrant_datamap_indices):\n                    if datamap_idx is None:\n                        continue\n                    mask = templateData[datamap_idx]  # GPU (h, w) with 0/1\n\n                    # If mask is all zeros, skip\n                    if int(cp.sum(mask)) == 0:\n                        continue\n\n                    # compute bounding box on mask\n                    rows, cols = cp.where(mask == 1)\n                    r_min = int(rows.min())\n                    r_max = int(rows.max()) + 1\n                    c_min = int(cols.min())\n                    c_max = int(cols.max()) + 1\n\n                    # get CPU part and move to GPU\n                    part_cpu = parts[q_idx]\n                    # If part shape mismatches bounding box, we will try to resize to fit\n                    ph, pw = part_cpu.shape[:2]\n                    box_h = r_max - r_min\n                    box_w = c_max - c_min\n                    if (ph != box_h) or (pw != box_w):\n                        # resize part to fit bounding box\n                        part_resized = cv2.resize(part_cpu, (box_w, box_h), interpolation=cv2.INTER_LINEAR)\n                    else:\n                        part_resized = part_cpu\n\n                    # move to GPU and convert to float32\n                    part_gpu = cp.asarray(part_resized.astype(np.float32))\n\n                    # paste into the imageArray[ q_idx, r_min:r_max, c_min:c_max ]\n                    imageArray[q_idx, r_min:r_max, c_min:c_max, :] = part_gpu\n\n                # Build data overlays (GPU)\n                dataPoints = altData_gpu(fullData_list, templateData)  # shape (4 + n_imagemap, h, w, 3)\n\n                # Now concatenate imageArray (4, ...) with the dataPoints (4 + n, ...)\n                # To avoid duplicating the first 4 from dataPoints (we kept placeholders), we only take indexes 4: of dataPoints\n                overlay_part = dataPoints[4:]  # shape (n_imagemap, h, w, 3)\n                Final_image3D = cp.concatenate((imageArray, overlay_part), axis=0)  # axis=0 => channels\n\n                # Sum over channel dimension to compose final image\n                Final_image = cp.sum(Final_image3D, axis=0)  # shape (h, w, 3), float32\n\n                # Clip and convert to uint8\n                Final_image_cpu = cp.asnumpy(Final_image)\n                Final_image_cpu = np.clip(Final_image_cpu, 0, 255).astype(np.uint8)\n\n                # Save\n                cv2.imwrite(newImagePath, Final_image_cpu)\n\n    print(f\"Finished template: {template_name}\")\n\nprint(\"All templates processed. Output at:\", newDataPath)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T01:03:23.107831Z","iopub.execute_input":"2025-12-27T01:03:23.109124Z","execution_failed":"2025-12-27T01:24:00.257Z"}},"outputs":[{"name":"stderr","text":"Templates:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processing template: /kaggle/input/templates/Templates/Template_5.png\n","output_type":"stream"},{"name":"stderr","text":"\nPatients:   0%|          | 0/189 [00:00<?, ?it/s]\u001b[A\nPatients:   1%|          | 1/189 [00:16<50:45, 16.20s/it]\u001b[A\nPatients:   1%|          | 2/189 [00:26<40:03, 12.85s/it]\u001b[A\nPatients:   2%|▏         | 3/189 [00:30<27:29,  8.87s/it]\u001b[A\nPatients:   2%|▏         | 4/189 [00:41<29:14,  9.48s/it]\u001b[A\nPatients:   3%|▎         | 5/189 [01:01<40:28, 13.20s/it]\u001b[A\nPatients:   3%|▎         | 6/189 [01:17<43:09, 14.15s/it]\u001b[A\nPatients:   4%|▎         | 7/189 [01:28<40:07, 13.23s/it]\u001b[A\nPatients:   4%|▍         | 8/189 [01:36<34:38, 11.48s/it]\u001b[A\nPatients:   5%|▍         | 9/189 [01:46<33:32, 11.18s/it]\u001b[A\nPatients:   5%|▌         | 10/189 [01:56<32:12, 10.80s/it]\u001b[A\nPatients:   6%|▌         | 11/189 [02:06<31:25, 10.59s/it]\u001b[A\nPatients:   6%|▋         | 12/189 [02:16<30:42, 10.41s/it]\u001b[A\nPatients:   7%|▋         | 13/189 [02:26<30:18, 10.34s/it]\u001b[A\nPatients:   7%|▋         | 14/189 [02:37<30:06, 10.32s/it]\u001b[A\nPatients:   8%|▊         | 15/189 [02:44<27:11,  9.38s/it]\u001b[A\nPatients:   8%|▊         | 16/189 [02:50<24:17,  8.42s/it]\u001b[A\nPatients:   9%|▉         | 17/189 [02:56<22:12,  7.75s/it]\u001b[A\nPatients:  10%|▉         | 18/189 [03:06<23:47,  8.35s/it]\u001b[A\nPatients:  10%|█         | 19/189 [03:16<25:16,  8.92s/it]\u001b[A\nPatients:  11%|█         | 20/189 [03:23<23:31,  8.35s/it]\u001b[A\nPatients:  11%|█         | 21/189 [03:26<18:38,  6.66s/it]\u001b[A\nPatients:  12%|█▏        | 22/189 [03:36<21:01,  7.55s/it]\u001b[A\nPatients:  12%|█▏        | 23/189 [03:46<23:18,  8.43s/it]\u001b[A\nPatients:  13%|█▎        | 24/189 [03:56<24:34,  8.94s/it]\u001b[A\nPatients:  13%|█▎        | 25/189 [04:06<25:16,  9.25s/it]\u001b[A\nPatients:  14%|█▍        | 26/189 [04:13<22:57,  8.45s/it]\u001b[A\nPatients:  14%|█▍        | 27/189 [04:22<23:51,  8.84s/it]\u001b[A\nPatients:  15%|█▍        | 28/189 [04:30<22:15,  8.30s/it]\u001b[A\nPatients:  15%|█▌        | 29/189 [04:39<23:16,  8.73s/it]\u001b[A\nPatients:  16%|█▌        | 30/189 [04:50<24:36,  9.28s/it]\u001b[A\nPatients:  16%|█▋        | 31/189 [05:00<24:46,  9.41s/it]\u001b[A\nPatients:  17%|█▋        | 32/189 [05:05<21:22,  8.17s/it]\u001b[A\nPatients:  17%|█▋        | 33/189 [05:15<22:41,  8.73s/it]\u001b[A\nPatients:  18%|█▊        | 34/189 [05:25<23:26,  9.08s/it]\u001b[A\nPatients:  19%|█▊        | 35/189 [05:35<23:59,  9.35s/it]\u001b[A\nPatients:  19%|█▉        | 36/189 [05:45<24:51,  9.75s/it]\u001b[A\nPatients:  20%|█▉        | 37/189 [05:56<25:09,  9.93s/it]\u001b[A\nPatients:  20%|██        | 38/189 [06:03<23:04,  9.17s/it]\u001b[A\nPatients:  21%|██        | 39/189 [06:09<20:14,  8.10s/it]\u001b[A\nPatients:  21%|██        | 40/189 [06:13<17:34,  7.08s/it]\u001b[A\nPatients:  22%|██▏       | 41/189 [06:23<19:37,  7.95s/it]\u001b[A\nPatients:  22%|██▏       | 42/189 [06:33<20:47,  8.49s/it]\u001b[A\nPatients:  23%|██▎       | 43/189 [06:43<21:56,  9.02s/it]\u001b[A\nPatients:  23%|██▎       | 44/189 [06:54<22:40,  9.38s/it]\u001b[A\nPatients:  24%|██▍       | 45/189 [07:04<22:52,  9.53s/it]\u001b[A\nPatients:  24%|██▍       | 46/189 [07:14<23:06,  9.69s/it]\u001b[A\nPatients:  25%|██▍       | 47/189 [07:24<23:11,  9.80s/it]\u001b[A\nPatients:  25%|██▌       | 48/189 [07:27<18:17,  7.78s/it]\u001b[A\nPatients:  26%|██▌       | 49/189 [07:37<19:42,  8.44s/it]\u001b[A\nPatients:  26%|██▋       | 50/189 [07:44<18:42,  8.07s/it]\u001b[A\nPatients:  27%|██▋       | 51/189 [07:54<20:07,  8.75s/it]\u001b[A\nPatients:  28%|██▊       | 52/189 [07:58<16:51,  7.38s/it]\u001b[A\nPatients:  28%|██▊       | 53/189 [08:09<18:37,  8.22s/it]\u001b[A\nPatients:  29%|██▊       | 54/189 [08:18<19:35,  8.71s/it]\u001b[A\nPatients:  29%|██▉       | 55/189 [08:28<20:11,  9.04s/it]\u001b[A\nPatients:  30%|██▉       | 56/189 [08:38<20:36,  9.30s/it]\u001b[A\nPatients:  30%|███       | 57/189 [08:46<19:31,  8.87s/it]\u001b[A\nPatients:  31%|███       | 58/189 [08:54<18:53,  8.65s/it]\u001b[A\nPatients:  31%|███       | 59/189 [09:04<19:28,  8.99s/it]\u001b[A\nPatients:  32%|███▏      | 60/189 [09:14<19:51,  9.24s/it]\u001b[A\nPatients:  32%|███▏      | 61/189 [09:23<19:56,  9.35s/it]\u001b[A\nPatients:  33%|███▎      | 62/189 [09:33<20:07,  9.51s/it]\u001b[A\nPatients:  33%|███▎      | 63/189 [09:43<20:16,  9.66s/it]\u001b[A\nPatients:  34%|███▍      | 64/189 [09:49<17:34,  8.44s/it]\u001b[A\nPatients:  34%|███▍      | 65/189 [09:55<15:51,  7.68s/it]\u001b[A\nPatients:  35%|███▍      | 66/189 [10:05<17:05,  8.34s/it]\u001b[A\nPatients:  35%|███▌      | 67/189 [10:12<16:21,  8.05s/it]\u001b[A\nPatients:  36%|███▌      | 68/189 [10:22<17:12,  8.53s/it]\u001b[A\nPatients:  37%|███▋      | 69/189 [10:32<17:54,  8.95s/it]\u001b[A\nPatients:  37%|███▋      | 70/189 [10:42<18:44,  9.45s/it]\u001b[A\nPatients:  38%|███▊      | 71/189 [10:52<19:03,  9.69s/it]\u001b[A\nPatients:  38%|███▊      | 72/189 [11:03<19:13,  9.85s/it]\u001b[A\nPatients:  39%|███▊      | 73/189 [11:13<19:12,  9.94s/it]\u001b[A\nPatients:  39%|███▉      | 74/189 [11:23<19:04,  9.95s/it]\u001b[A\nPatients:  40%|███▉      | 75/189 [11:27<15:42,  8.27s/it]\u001b[A\nPatients:  40%|████      | 76/189 [11:37<16:33,  8.79s/it]\u001b[A\nPatients:  41%|████      | 77/189 [11:48<17:27,  9.35s/it]\u001b[A\nPatients:  41%|████▏     | 78/189 [11:54<15:19,  8.28s/it]\u001b[A\nPatients:  42%|████▏     | 79/189 [12:04<16:13,  8.85s/it]\u001b[A\nPatients:  42%|████▏     | 80/189 [12:14<16:51,  9.28s/it]\u001b[A\nPatients:  43%|████▎     | 81/189 [12:19<14:27,  8.03s/it]\u001b[A\nPatients:  43%|████▎     | 82/189 [12:30<15:32,  8.71s/it]\u001b[A\nPatients:  44%|████▍     | 83/189 [12:40<16:26,  9.31s/it]\u001b[A\nPatients:  44%|████▍     | 84/189 [12:51<16:59,  9.71s/it]\u001b[A\nPatients:  45%|████▍     | 85/189 [12:57<14:55,  8.61s/it]\u001b[A\nPatients:  46%|████▌     | 86/189 [13:08<16:13,  9.46s/it]\u001b[A\nPatients:  46%|████▌     | 87/189 [13:20<17:01, 10.02s/it]\u001b[A\nPatients:  47%|████▋     | 88/189 [13:31<17:38, 10.48s/it]\u001b[A\nPatients:  47%|████▋     | 89/189 [13:38<15:32,  9.33s/it]\u001b[A\nPatients:  48%|████▊     | 90/189 [13:42<13:02,  7.90s/it]\u001b[A\nPatients:  48%|████▊     | 91/189 [13:53<14:26,  8.84s/it]\u001b[A\nPatients:  49%|████▊     | 92/189 [14:04<14:52,  9.20s/it]\u001b[A\nPatients:  49%|████▉     | 93/189 [14:07<11:49,  7.40s/it]\u001b[A\nPatients:  50%|████▉     | 94/189 [14:17<13:00,  8.22s/it]\u001b[A\nPatients:  50%|█████     | 95/189 [14:24<12:24,  7.92s/it]\u001b[A\nPatients:  51%|█████     | 96/189 [14:35<13:34,  8.76s/it]\u001b[A\nPatients:  51%|█████▏    | 97/189 [14:43<13:08,  8.57s/it]\u001b[A\nPatients:  52%|█████▏    | 98/189 [14:54<13:56,  9.19s/it]\u001b[A\nPatients:  52%|█████▏    | 99/189 [15:00<12:26,  8.30s/it]\u001b[A\nPatients:  53%|█████▎    | 100/189 [15:10<13:07,  8.85s/it]\u001b[A\nPatients:  53%|█████▎    | 101/189 [15:18<12:43,  8.67s/it]\u001b[A\nPatients:  54%|█████▍    | 102/189 [15:24<11:33,  7.97s/it]\u001b[A\nPatients:  54%|█████▍    | 103/189 [15:35<12:19,  8.60s/it]\u001b[A\nPatients:  55%|█████▌    | 104/189 [15:45<13:01,  9.19s/it]\u001b[A\nPatients:  56%|█████▌    | 105/189 [15:55<13:05,  9.36s/it]\u001b[A\nPatients:  56%|█████▌    | 106/189 [16:05<13:13,  9.56s/it]\u001b[A\nPatients:  57%|█████▋    | 107/189 [16:15<13:15,  9.70s/it]\u001b[A\nPatients:  57%|█████▋    | 108/189 [16:25<13:13,  9.80s/it]\u001b[A\nPatients:  58%|█████▊    | 109/189 [16:35<13:11,  9.89s/it]\u001b[A\nPatients:  58%|█████▊    | 110/189 [16:46<13:17, 10.09s/it]\u001b[A\nPatients:  59%|█████▊    | 111/189 [16:49<10:38,  8.19s/it]\u001b[A\nPatients:  59%|█████▉    | 112/189 [16:56<09:44,  7.60s/it]\u001b[A\nPatients:  60%|█████▉    | 113/189 [17:00<08:27,  6.67s/it]\u001b[A\nPatients:  60%|██████    | 114/189 [17:12<10:14,  8.19s/it]\u001b[A\nPatients:  61%|██████    | 115/189 [17:22<10:52,  8.82s/it]\u001b[A\nPatients:  61%|██████▏   | 116/189 [17:33<11:17,  9.28s/it]\u001b[A\nPatients:  62%|██████▏   | 117/189 [17:43<11:39,  9.71s/it]\u001b[A\nPatients:  62%|██████▏   | 118/189 [17:54<11:49,  9.99s/it]\u001b[A\nPatients:  63%|██████▎   | 119/189 [18:04<11:49, 10.13s/it]\u001b[A\nPatients:  63%|██████▎   | 120/189 [18:15<11:40, 10.15s/it]\u001b[A\nPatients:  64%|██████▍   | 121/189 [18:21<10:10,  8.98s/it]\u001b[A\nPatients:  65%|██████▍   | 122/189 [18:28<09:16,  8.31s/it]\u001b[A\nPatients:  65%|██████▌   | 123/189 [18:38<09:54,  9.01s/it]\u001b[A\nPatients:  66%|██████▌   | 124/189 [18:42<08:12,  7.57s/it]\u001b[A\nPatients:  66%|██████▌   | 125/189 [18:53<09:06,  8.54s/it]\u001b[A\nPatients:  67%|██████▋   | 126/189 [18:59<08:11,  7.80s/it]\u001b[A\nPatients:  67%|██████▋   | 127/189 [19:10<09:02,  8.75s/it]\u001b[A\nPatients:  68%|██████▊   | 128/189 [19:20<09:16,  9.13s/it]\u001b[A\nPatients:  68%|██████▊   | 129/189 [19:31<09:30,  9.51s/it]\u001b[A\nPatients:  69%|██████▉   | 130/189 [19:41<09:43,  9.89s/it]\u001b[A\nPatients:  69%|██████▉   | 131/189 [19:52<09:42, 10.04s/it]\u001b[A\nPatients:  70%|██████▉   | 132/189 [20:02<09:27,  9.96s/it]\u001b[A\nPatients:  70%|███████   | 133/189 [20:12<09:21, 10.03s/it]\u001b[A\nPatients:  71%|███████   | 134/189 [20:21<09:02,  9.87s/it]\u001b[A\nPatients:  71%|███████▏  | 135/189 [20:31<08:54,  9.89s/it]\u001b[A","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!zip -rq /kaggle/working/Dataset_5_Templates.zip /kaggle/working/NewDataset_gpu","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-27T01:24:00.258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print\"DONE\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-27T01:24:00.258Z"}},"outputs":[],"execution_count":null}]}